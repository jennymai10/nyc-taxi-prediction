{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Engineering\n",
    "\n",
    "This notebook performs data cleaning and feature engineering on taxi trip data. Key steps include:\n",
    "\n",
    "1. **Initialization**: Setting up a Spark session for data processing.\n",
    "2. **Data Loading**: Reading and inspecting the Parquet file.\n",
    "3. **Descriptive Statistics**: Analyzing the dataset for central tendencies and outliers.\n",
    "4. **Missing Values**: Identifying and dropping rows with missing data.\n",
    "5. **Data Filtering**: Removing invalid entries based on specific criteria (e.g., fare amount, trip distance).\n",
    "6. **Feature Engineering**: Creating new features like trip duration, day of the week, and interaction terms.\n",
    "7. **Final Dataset**: Saving the cleaned and processed data in Parquet format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries and Functions\n",
    "\n",
    "The following libraries and functions are imported to support various data manipulation and aggregation tasks:\n",
    "- `SparkSession`: The entry point to programming with Spark.\n",
    "- `functions` as `F`: Importing PySpark SQL functions with a shorthand to make function calls more concise.\n",
    "- Specific functions such as `col`, `sum`, `approx_count_distinct`, `hour`, `dayofweek`, `datediff`, `lit`, `unix_timestamp`, and `when`, which will be used for column operations, aggregations, and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, sum, approx_count_distinct, hour, dayofweek, datediff, lit, unix_timestamp, when"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we initialize a Spark session that will be used for all subsequent data processing tasks in this notebook. The Spark session is configured with several important settings that optimize performance and ensure consistency in data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/25 12:15:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1\")  # Setting the application name for the Spark session\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)  # Enabling eager evaluation for interactive querying\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")  # Caching Parquet metadata to speed up file reading\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")  # Setting the session's time zone to UTC for consistency\n",
    "    .getOrCreate()  # Creating the Spark session or retrieving an existing one\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(sdf: DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Returns the shape of a Spark DataFrame as a tuple (number of rows, number of columns).\n",
    "\n",
    "    :param sdf: Spark DataFrame\n",
    "    :return: String stating the shape of sdf\n",
    "    \"\"\"\n",
    "    num_rows = sdf.count()\n",
    "    num_columns = len(sdf.columns)\n",
    "    print(f\"Shape of the DataFrame: {num_rows} rows, {num_columns} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Examination of the Dataset\n",
    "\n",
    "First, we load the preprocessed Parquet file into a Spark DataFrame and then count the number of records (rows) in the DataFrame. This gives us an initial sense of the dataset's size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:=======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame: 19325003 rows, 19 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed Parquet file into a Spark DataFrame\n",
    "sdf = spark.read.parquet('/Users/jennymai/Desktop/data_sci/mast_project1/data/raw')\n",
    "\n",
    "shape(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:37:35</td><td>2022-12-01 00:47:35</td><td>1.0</td><td>2.0</td><td>1.0</td><td>N</td><td>170</td><td>237</td><td>1</td><td>8.5</td><td>3.0</td><td>0.5</td><td>3.1</td><td>0.0</td><td>0.3</td><td>15.4</td><td>2.5</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:34:35</td><td>2022-12-01 00:55:21</td><td>0.0</td><td>8.4</td><td>1.0</td><td>N</td><td>138</td><td>141</td><td>2</td><td>26.0</td><td>4.25</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>31.05</td><td>2.5</td><td>1.25</td></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:33:26</td><td>2022-12-01 00:37:34</td><td>1.0</td><td>0.8</td><td>1.0</td><td>N</td><td>140</td><td>140</td><td>1</td><td>5.0</td><td>3.0</td><td>0.5</td><td>1.76</td><td>0.0</td><td>0.3</td><td>10.56</td><td>2.5</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:45:51</td><td>2022-12-01 00:53:16</td><td>1.0</td><td>3.0</td><td>1.0</td><td>N</td><td>141</td><td>79</td><td>3</td><td>10.0</td><td>3.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>13.8</td><td>2.5</td><td>0.0</td></tr>\n",
       "<tr><td>2</td><td>2022-12-01 00:49:49</td><td>2022-12-01 00:54:13</td><td>1.0</td><td>0.76</td><td>1.0</td><td>N</td><td>261</td><td>231</td><td>1</td><td>5.0</td><td>0.5</td><td>0.5</td><td>1.76</td><td>0.0</td><td>0.3</td><td>10.56</td><td>2.5</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:25:25</td><td>2022-12-01 00:35:38</td><td>2.0</td><td>2.6</td><td>1.0</td><td>N</td><td>237</td><td>164</td><td>1</td><td>10.5</td><td>3.0</td><td>0.5</td><td>4.25</td><td>0.0</td><td>0.3</td><td>18.55</td><td>2.5</td><td>0.0</td></tr>\n",
       "<tr><td>2</td><td>2022-12-01 00:05:37</td><td>2022-12-01 00:10:48</td><td>1.0</td><td>0.94</td><td>1.0</td><td>N</td><td>79</td><td>144</td><td>1</td><td>5.5</td><td>0.5</td><td>0.5</td><td>1.86</td><td>0.0</td><td>0.3</td><td>11.16</td><td>2.5</td><td>0.0</td></tr>\n",
       "<tr><td>2</td><td>2022-12-01 00:20:12</td><td>2022-12-01 00:28:49</td><td>1.0</td><td>2.09</td><td>1.0</td><td>N</td><td>79</td><td>186</td><td>1</td><td>9.0</td><td>0.5</td><td>0.5</td><td>2.0</td><td>0.0</td><td>0.3</td><td>14.8</td><td>2.5</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:00:54</td><td>2022-12-01 00:05:41</td><td>1.0</td><td>0.8</td><td>1.0</td><td>N</td><td>142</td><td>143</td><td>1</td><td>5.5</td><td>3.0</td><td>0.5</td><td>1.85</td><td>0.0</td><td>0.3</td><td>11.15</td><td>2.5</td><td>0.0</td></tr>\n",
       "<tr><td>2</td><td>2022-12-01 00:11:23</td><td>2022-12-01 00:30:00</td><td>1.0</td><td>7.62</td><td>1.0</td><td>N</td><td>138</td><td>255</td><td>1</td><td>24.0</td><td>0.5</td><td>0.5</td><td>5.31</td><td>0.0</td><td>0.3</td><td>31.86</td><td>0.0</td><td>1.25</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|       1| 2022-12-01 00:37:35|  2022-12-01 00:47:35|            1.0|          2.0|       1.0|                 N|         170|         237|           1|        8.5|  3.0|    0.5|       3.1|         0.0|                  0.3|        15.4|                 2.5|        0.0|\n",
       "|       1| 2022-12-01 00:34:35|  2022-12-01 00:55:21|            0.0|          8.4|       1.0|                 N|         138|         141|           2|       26.0| 4.25|    0.5|       0.0|         0.0|                  0.3|       31.05|                 2.5|       1.25|\n",
       "|       1| 2022-12-01 00:33:26|  2022-12-01 00:37:34|            1.0|          0.8|       1.0|                 N|         140|         140|           1|        5.0|  3.0|    0.5|      1.76|         0.0|                  0.3|       10.56|                 2.5|        0.0|\n",
       "|       1| 2022-12-01 00:45:51|  2022-12-01 00:53:16|            1.0|          3.0|       1.0|                 N|         141|          79|           3|       10.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        13.8|                 2.5|        0.0|\n",
       "|       2| 2022-12-01 00:49:49|  2022-12-01 00:54:13|            1.0|         0.76|       1.0|                 N|         261|         231|           1|        5.0|  0.5|    0.5|      1.76|         0.0|                  0.3|       10.56|                 2.5|        0.0|\n",
       "|       1| 2022-12-01 00:25:25|  2022-12-01 00:35:38|            2.0|          2.6|       1.0|                 N|         237|         164|           1|       10.5|  3.0|    0.5|      4.25|         0.0|                  0.3|       18.55|                 2.5|        0.0|\n",
       "|       2| 2022-12-01 00:05:37|  2022-12-01 00:10:48|            1.0|         0.94|       1.0|                 N|          79|         144|           1|        5.5|  0.5|    0.5|      1.86|         0.0|                  0.3|       11.16|                 2.5|        0.0|\n",
       "|       2| 2022-12-01 00:20:12|  2022-12-01 00:28:49|            1.0|         2.09|       1.0|                 N|          79|         186|           1|        9.0|  0.5|    0.5|       2.0|         0.0|                  0.3|        14.8|                 2.5|        0.0|\n",
       "|       1| 2022-12-01 00:00:54|  2022-12-01 00:05:41|            1.0|          0.8|       1.0|                 N|         142|         143|           1|        5.5|  3.0|    0.5|      1.85|         0.0|                  0.3|       11.15|                 2.5|        0.0|\n",
       "|       2| 2022-12-01 00:11:23|  2022-12-01 00:30:00|            1.0|         7.62|       1.0|                 N|         138|         255|           1|       24.0|  0.5|    0.5|      5.31|         0.0|                  0.3|       31.86|                 0.0|       1.25|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics of the DataFrame\n",
    "\n",
    "We generate descriptive statistics for the columns in the DataFrame. This includes metrics like count, mean, standard deviation, min, and max values for each column. The `.limit(25)` function is used to restrict the output to the first 25 rows of the summary, which is useful for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/25 12:16:20 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>VendorID</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th></tr>\n",
       "<tr><td>count</td><td>19325003</td><td>18749713</td><td>19325003</td><td>18749713</td><td>18749713</td><td>19325003</td><td>19325003</td><td>19325003</td><td>19325003</td><td>19325003</td><td>19325003</td><td>19325003</td><td>19325003</td><td>19325003</td><td>19325003</td><td>18749713</td><td>18749713</td></tr>\n",
       "<tr><td>mean</td><td>1.7366218261389144</td><td>1.3775969797511034</td><td>4.4731091617420455</td><td>1.511516416277945</td><td>NULL</td><td>165.81878698802788</td><td>163.8886903665681</td><td>1.1913664903441412</td><td>8.619574211193223</td><td>1.37918114734575</td><td>0.48740718177380965</td><td>12.481317347272658</td><td>0.5587781290405625</td><td>0.786410356575844</td><td>26.085003642540244</td><td>2.2763282696647145</td><td>0.11028039469190809</td></tr>\n",
       "<tr><td>stddev</td><td>0.4503651288017578</td><td>0.9115429260790552</td><td>363.4348135144023</td><td>6.521382764229247</td><td>NULL</td><td>64.37805416509637</td><td>69.91840539145225</td><td>0.5403365296476417</td><td>31985.042259392096</td><td>1.6916961295284452</td><td>0.10260727239281353</td><td>31985.02206297459</td><td>2.1046864872475637</td><td>0.3492941909534933</td><td>21.746516925703688</td><td>0.7712032427241626</td><td>0.37471728113382</td></tr>\n",
       "<tr><td>min</td><td>1</td><td>0.0</td><td>0.0</td><td>1.0</td><td>N</td><td>1</td><td>1</td><td>0</td><td>-1.33391414E8</td><td>-7.5</td><td>-0.5</td><td>-110.0</td><td>-73.3</td><td>-1.0</td><td>-1635.8</td><td>-2.5</td><td>-1.75</td></tr>\n",
       "<tr><td>max</td><td>6</td><td>9.0</td><td>335004.33</td><td>99.0</td><td>Y</td><td>265</td><td>265</td><td>5</td><td>5901.74</td><td>96.38</td><td>53.16</td><td>1.3339136353E8</td><td>655.55</td><td>1.0</td><td>5902.54</td><td>2.75</td><td>1.75</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+------------------+------------------+------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-------------------+------------------+------------------+---------------------+------------------+--------------------+-------------------+\n",
       "|summary|          VendorID|   passenger_count|     trip_distance|       RatecodeID|store_and_fwd_flag|      PULocationID|     DOLocationID|      payment_type|       fare_amount|             extra|            mta_tax|        tip_amount|      tolls_amount|improvement_surcharge|      total_amount|congestion_surcharge|        airport_fee|\n",
       "+-------+------------------+------------------+------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-------------------+------------------+------------------+---------------------+------------------+--------------------+-------------------+\n",
       "|  count|          19325003|          18749713|          19325003|         18749713|          18749713|          19325003|         19325003|          19325003|          19325003|          19325003|           19325003|          19325003|          19325003|             19325003|          19325003|            18749713|           18749713|\n",
       "|   mean|1.7366218261389144|1.3775969797511034|4.4731091617420455|1.511516416277945|              NULL|165.81878698802788|163.8886903665681|1.1913664903441412| 8.619574211193223|  1.37918114734575|0.48740718177380965|12.481317347272658|0.5587781290405625|    0.786410356575844|26.085003642540244|  2.2763282696647145|0.11028039469190809|\n",
       "| stddev|0.4503651288017578|0.9115429260790552| 363.4348135144023|6.521382764229247|              NULL| 64.37805416509637|69.91840539145225|0.5403365296476417|31985.042259392096|1.6916961295284452|0.10260727239281353| 31985.02206297459|2.1046864872475637|   0.3492941909534933|21.746516925703688|  0.7712032427241626|   0.37471728113382|\n",
       "|    min|                 1|               0.0|               0.0|              1.0|                 N|                 1|                1|                 0|     -1.33391414E8|              -7.5|               -0.5|            -110.0|             -73.3|                 -1.0|           -1635.8|                -2.5|              -1.75|\n",
       "|    max|                 6|               9.0|         335004.33|             99.0|                 Y|               265|              265|                 5|           5901.74|             96.38|              53.16|    1.3339136353E8|            655.55|                  1.0|           5902.54|                2.75|               1.75|\n",
       "+-------+------------------+------------------+------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-------------------+------------------+------------------+---------------------+------------------+--------------------+-------------------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate descriptive statistics for the DataFrame, limiting the output to the first 25 rows\n",
    "sdf.describe().limit(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. **VendorID**\n",
    "- **Count**: 19,325,003 non-null entries.\n",
    "- **Mean**: 1.7366, indicating the average value is slightly above 1, suggesting that there may be two main vendor IDs.\n",
    "- **Stddev**: 0.4504\n",
    "- **Min**: 1, indicating that VendorID values start at 1.\n",
    "- **Max**: 6, indicating a maximum VendorID of 6. This is likely an error because according to the Data Dictionary, VendorID has 2 valid values of either 1 or 2.\n",
    "\n",
    "#### 2. **passenger_count**\n",
    "- **Count**: 18,749,713 non-null entries, indicating some missing values.\n",
    "- **Mean**: 1.3776, suggesting that on average, there is around 1 to 2 passengers per trip.\n",
    "- **Stddev**: 0.9115, moderate variability.\n",
    "- **Min**: 0, indicating there are records with zero passengers, which could be an error.\n",
    "- **Max**: 9, suggesting a maximum of 9 passengers in some trips. As per research a maximum of 6 passengers is permitted by law.\n",
    "\n",
    "#### 3. **trip_distance**\n",
    "- **Count**: 19,325,003 non-null entries.\n",
    "- **Mean**: 4.4731, the average trip distance is approximately 4.47 miles.\n",
    "- **Stddev**: 363.43, suggesting there is significant variability in trip distances, which could be due to outliers.\n",
    "- **Min**: 0.0, indicating that some trips have a recorded distance of 0 miles, which does not look valid.\n",
    "- **Max**: 335004.33 miles, which is likely an outlier or a data error.\n",
    "\n",
    "#### 4. **RatecodeID**\n",
    "- **Count**: 18,749,713 non-null entries, some missing values.\n",
    "- **Mean**: 1.5116.\n",
    "- **Stddev**: 6.5214.\n",
    "- **Min**: 1, indicating the lowest RatecodeID is 1.\n",
    "- **Max**: 99, which is unusually high and could indicate a special code or error.\n",
    "\n",
    "#### 5. **store_and_fwd_flag**\n",
    "- **Count**: 18,749,713 non-null entries, some missing values.\n",
    "\n",
    "#### 6. **PULocationID & DOLocationID**\n",
    "- **Count**: 19,325,003 non-null entries.\n",
    "- **Mean**: Average values of 165.82 (PU) and 163.89 (DO) suggest these IDs typically refer to certain locations.\n",
    "- **Stddev**: Standard deviations of 64.38 (PU) and 69.91 (DO).\n",
    "- **Min**: 1, showing that the location IDs start from 1.\n",
    "- **Max**: 265, indicating the highest location ID recorded.\n",
    "\n",
    "#### 7. **payment_type**\n",
    "- **Count**: 19,325,003 non-null entries.\n",
    "- **Mean**: 1.1914, suggesting that most payments are made with a primary payment type (likely 1 or 2).\n",
    "- **Stddev**: 0.5403.\n",
    "- **Min**: 1, indicating the minimum payment type recorded.\n",
    "- **Max**: 5, suggesting there are up to 5 different payment types in the dataset.\n",
    "\n",
    "#### 8. **fare_amount**\n",
    "- **Count**: 19,325,003 non-null entries.\n",
    "- **Mean**: 8.6196, indicating the average fare is around $8.62.\n",
    "- **Stddev**: 31985.04, which is unusually high and suggests the presence of outliers or extreme values.\n",
    "- **Min**: -1.33391414E8, which is likely an error, as a negative fare amount is not typical.\n",
    "- **Max**: 5901.74, indicating the highest fare recorded. This is likely an outlier as well.\n",
    "\n",
    "#### 9. **extra**\n",
    "According to the Data Dictionary, this only includes the $0.50 and $1 rush hour and overnight charges.\n",
    "- **Count**: 19,325,003 non-null entries.\n",
    "- **Mean**: 1.3791.\n",
    "- **Stddev**: 1.6917.\n",
    "- **Min**: -7.5, which might indicate an error.\n",
    "- **Max**: 96.38, invalid values. \n",
    "\n",
    "#### 10. **mta_tax**\n",
    "According to the Data Dictionary, $0.50 MTA tax that is automatically triggered based on the metered rate in use.\n",
    "- **Count**: 19,325,003 non-null entries.\n",
    "- **Mean**: 0.4874.\n",
    "- **Stddev**: 0.1026.\n",
    "- **Min**: -0.5, which might be an error, as negative tax is not expected.\n",
    "- **Max**: 53.16, invalid values for an MTA tax.\n",
    "\n",
    "#### 11. **tip_amount**\n",
    "This field is automatically populated for credit card tips. Cash tips are not included.\n",
    "- **Count**: 19,325,003 non-null entries.\n",
    "- **Mean**: 12.48, suggesting an average tip of around $12.48.\n",
    "- **Stddev**: 31985.02, indicating the presence of outliers or extreme values.\n",
    "- **Min**: -110.0, which could be an error.\n",
    "- **Max**: 1.33391363E8, indicating an exceptionally high tip, likely due to a data entry error.\n",
    "\n",
    "#### 12. **tolls_amount**\n",
    "- **Count**: 19,325,003 non-null entries.\n",
    "- **Mean**: 0.5588, suggesting an average toll amount of around 56 cents.\n",
    "- **Stddev**: 2.1047, indicating some variability.\n",
    "- **Min**: -73.3, which could be an error.\n",
    "- **Max**: 655.55, representing the highest toll recorded, likely an outlier.\n",
    "\n",
    "#### 13. **improvement_surcharge**\n",
    "$0.30 improvement surcharge assessed trips at the flag drop. The improvement surcharge began being levied in 2015.\n",
    "- **Count**: 19,325,003 non-null entries.\n",
    "- **Mean**: 0.7864, indicating a typical surcharge of around 79 cents.\n",
    "- **Stddev**: 0.3492, showing minimal variability.\n",
    "- **Min**: -1.0, possibly an error.\n",
    "- **Max**: 1.0, some invalid values.\n",
    "\n",
    "#### 14. **total_amount**\n",
    "- **Count**: 19,325,003 non-null entries.\n",
    "- **Mean**: 26.0850, indicating an average total fare of around $26.09.\n",
    "- **Stddev**: 21.7465.\n",
    "- **Min**: -1635.8, likely an error.\n",
    "- **Max**: 5902.54, can be an outlier.\n",
    "\n",
    "#### 15. **congestion_surcharge**\n",
    "- **Count**: 18,749,713 non-null entries.\n",
    "- **Mean**: 2.2763, showing an average congestion surcharge of around $2.28.\n",
    "- **Stddev**: 0.7712, indicating some variability in the surcharge amount.\n",
    "- **Min**: -2.5, possibly an error.\n",
    "- **Max**: 2.75, which seems reasonable for a congestion surcharge.\n",
    "\n",
    "#### 16. **airport_fee**\n",
    "$1.25 for pick up only at LaGuardia and John F. Kennedy Airports\n",
    "- **Count**: 18,749,713 non-null entries, some missing values.\n",
    "- **Mean**: 0.1103, indicating a small average airport fee.\n",
    "- **Stddev**: 0.3747, showing some variability.\n",
    "- **Min**: -1.75, which might be an error.\n",
    "- **Max**: 1.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Approximate Median Values for Selected Columns\n",
    "\n",
    "We calculate the approximate median values for a selected list of numeric columns. The median is a useful measure of central tendency, especially in skewed distributions. We use Spark's `approxQuantile` function for efficiency, which approximates the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate median value of column 'trip_distance' is: 1.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate median value of column 'fare_amount' is: 12.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate median value of column 'extra' is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate median value of column 'mta_tax' is: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate median value of column 'tolls_amount' is: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate median value of column 'improvement_surcharge' is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate median value of column 'total_amount' is: 19.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate median value of column 'congestion_surcharge' is: 2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate median value of column 'airport_fee' is: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate median value of column 'passenger_count' is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# List of columns for which we want to calculate the approximate median\n",
    "column_list = ['trip_distance', 'fare_amount', 'extra', 'mta_tax', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'airport_fee', 'passenger_count']\n",
    "\n",
    "# Calculate and print the approximate median for each column in the list\n",
    "for column in column_list:\n",
    "    median_approx = sdf.approxQuantile(column, [0.5], 0.01)[0]  # Approximate median calculation\n",
    "    print(f\"The approximate median value of column '{column}' is: {median_approx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median provides a central value in the dataset, useful for understanding typical values without the influence of outliers.\n",
    "\n",
    "- **trip_distance**: 1.8 miles\n",
    "  - Most trips are short, with half being less than 1.8 miles.\n",
    "\n",
    "- **fare_amount**: $12.8\n",
    "  - Typical fare is around $12.8, higher than the mean, indicating some higher fare trips.\n",
    "\n",
    "- **extra**: $1.0\n",
    "  - Common additional charge, with half of the trips incurring $1.0 or less.\n",
    "\n",
    "- **mta_tax**: $0.5\n",
    "  - Standard MTA tax applied to most trips.\n",
    "\n",
    "- **tolls_amount**: $0.0\n",
    "  - Most trips do not include tolls.\n",
    "\n",
    "- **improvement_surcharge**: $1.0\n",
    "  - Typical surcharge applied consistently.\n",
    "\n",
    "- **total_amount**: $19.32\n",
    "  - Common total charge, reflecting fare, taxes, and surcharges.\n",
    "\n",
    "- **congestion_surcharge**: $2.5\n",
    "  - Regularly applied charge in congested areas.\n",
    "\n",
    "- **airport_fee**: $0.0\n",
    "  - Majority of trips do not involve airport fees.\n",
    "\n",
    "- **passenger_count**: 1.0\n",
    "  - Most trips involve a single passenger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Missing Values in the DataFrame\n",
    "\n",
    "We check for missing (null) values in each column of the DataFrame. This step is crucial for data cleaning, as missing values can impact the accuracy of models and analyses. The output shows the count of null values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       0|                   0|                    0|         575290|            0|    575290|            575290|           0|           0|           0|          0|    0|      0|         0|           0|                    0|           0|              575290|     575290|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Select columns and count the number of null values in each\n",
    "sdf.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in sdf.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`passenger_count`, `RatecodeID`, `store_and_fwd_flag`, `congestion_surcharge`, `airport_fee`: all have 575,290 missing entries.\n",
    "  \n",
    "=>  These columns have missing data that may need imputation or removal to ensure data quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Rows with Missing Values\n",
    "\n",
    "We remove any rows that contain missing values. The decision to drop rows with missing values was made to ensure the dataset's integrity, providing a complete and consistent basis for analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame: 18749713 rows, 19 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sdf = sdf.dropna()\n",
    "shape(sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach simplifies the data preparation process by avoiding the need for complex imputation methods, due to the availability of plenty of data.\n",
    "\n",
    "As a result, the DataFrame now contains 18,749,713 rows and 19 columns, all of which are complete and ready for further processing and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Approximate Unique Values in Each Column\n",
    "\n",
    "We compute the approximate number of unique values in each column. This is useful to understand the diversity or cardinality of the data within each column, which can inform outlier or error presence, feature selection, or further data processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate unique values in each column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VendorID: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpep_pickup_datetime: 9679197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpep_dropoff_datetime: 9788423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger_count: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip_distance: 6446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RatecodeID: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_and_fwd_flag: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PULocationID: 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOLocationID: 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payment_type: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fare_amount: 6385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra: 121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mta_tax: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tip_amount: 6016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tolls_amount: 1805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improvement_surcharge: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_amount: 24995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congestion_surcharge: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 92:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airport_fee: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print('Approximate unique values in each column')\n",
    "for column in sdf.columns:\n",
    "    distinct_count = sdf.select(approx_count_distinct(column)).collect()[0][0]\n",
    "    print(f\"{column}: {distinct_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by Variables and Counting Occurrences\n",
    "\n",
    "Groups the DataFrame by the `passenger_count`, `mta_tax`, and `RatecodeID` columns and counts the occurrences of each group. The result is ordered by the count in descending order, and the top 25 rows are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>passenger_count</th><th>count</th></tr>\n",
       "<tr><td>1.0</td><td>14031997</td></tr>\n",
       "<tr><td>2.0</td><td>2848258</td></tr>\n",
       "<tr><td>3.0</td><td>718882</td></tr>\n",
       "<tr><td>4.0</td><td>377282</td></tr>\n",
       "<tr><td>0.0</td><td>321354</td></tr>\n",
       "<tr><td>5.0</td><td>276668</td></tr>\n",
       "<tr><td>6.0</td><td>175111</td></tr>\n",
       "<tr><td>8.0</td><td>72</td></tr>\n",
       "<tr><td>7.0</td><td>61</td></tr>\n",
       "<tr><td>9.0</td><td>28</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+--------+\n",
       "|passenger_count|   count|\n",
       "+---------------+--------+\n",
       "|            1.0|14031997|\n",
       "|            2.0| 2848258|\n",
       "|            3.0|  718882|\n",
       "|            4.0|  377282|\n",
       "|            0.0|  321354|\n",
       "|            5.0|  276668|\n",
       "|            6.0|  175111|\n",
       "|            8.0|      72|\n",
       "|            7.0|      61|\n",
       "|            9.0|      28|\n",
       "+---------------+--------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.groupBy('passenger_count').count().orderBy('count', ascending=False).limit(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>mta_tax</th><th>count</th></tr>\n",
       "<tr><td>0.5</td><td>18405655</td></tr>\n",
       "<tr><td>0.0</td><td>177194</td></tr>\n",
       "<tr><td>-0.5</td><td>157022</td></tr>\n",
       "<tr><td>0.8</td><td>9203</td></tr>\n",
       "<tr><td>1.3</td><td>404</td></tr>\n",
       "<tr><td>1.5</td><td>125</td></tr>\n",
       "<tr><td>0.3</td><td>61</td></tr>\n",
       "<tr><td>4.0</td><td>18</td></tr>\n",
       "<tr><td>3.3</td><td>7</td></tr>\n",
       "<tr><td>3.0</td><td>5</td></tr>\n",
       "<tr><td>0.05</td><td>5</td></tr>\n",
       "<tr><td>1.6</td><td>3</td></tr>\n",
       "<tr><td>1.05</td><td>3</td></tr>\n",
       "<tr><td>3.5</td><td>2</td></tr>\n",
       "<tr><td>1.0</td><td>1</td></tr>\n",
       "<tr><td>2.0</td><td>1</td></tr>\n",
       "<tr><td>5.25</td><td>1</td></tr>\n",
       "<tr><td>16.55</td><td>1</td></tr>\n",
       "<tr><td>53.16</td><td>1</td></tr>\n",
       "<tr><td>1.09</td><td>1</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+--------+\n",
       "|mta_tax|   count|\n",
       "+-------+--------+\n",
       "|    0.5|18405655|\n",
       "|    0.0|  177194|\n",
       "|   -0.5|  157022|\n",
       "|    0.8|    9203|\n",
       "|    1.3|     404|\n",
       "|    1.5|     125|\n",
       "|    0.3|      61|\n",
       "|    4.0|      18|\n",
       "|    3.3|       7|\n",
       "|    3.0|       5|\n",
       "|   0.05|       5|\n",
       "|    1.6|       3|\n",
       "|   1.05|       3|\n",
       "|    3.5|       2|\n",
       "|    1.0|       1|\n",
       "|    2.0|       1|\n",
       "|   5.25|       1|\n",
       "|  16.55|       1|\n",
       "|  53.16|       1|\n",
       "|   1.09|       1|\n",
       "+-------+--------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.groupBy('mta_tax').count().orderBy('count', ascending=False).limit(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>RatecodeID</th><th>count</th></tr>\n",
       "<tr><td>1.0</td><td>17710228</td></tr>\n",
       "<tr><td>2.0</td><td>747019</td></tr>\n",
       "<tr><td>5.0</td><td>121197</td></tr>\n",
       "<tr><td>99.0</td><td>83207</td></tr>\n",
       "<tr><td>3.0</td><td>59635</td></tr>\n",
       "<tr><td>4.0</td><td>28356</td></tr>\n",
       "<tr><td>6.0</td><td>71</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+--------+\n",
       "|RatecodeID|   count|\n",
       "+----------+--------+\n",
       "|       1.0|17710228|\n",
       "|       2.0|  747019|\n",
       "|       5.0|  121197|\n",
       "|      99.0|   83207|\n",
       "|       3.0|   59635|\n",
       "|       4.0|   28356|\n",
       "|       6.0|      71|\n",
       "+----------+--------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.groupBy('RatecodeID').count().orderBy('count', ascending=False).limit(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Quantiles for Fare Amount\n",
    "\n",
    "Calculates the 50th, 75th, 90th, 95th, and 99th percentiles of the `fare_amount` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 113:======================================>                  (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50th percentile (median): 12.5\n",
      "75th percentile: 19.8\n",
      "90th percentile: 38.0\n",
      "95th percentile: 54.1\n",
      "99th percentile: 5901.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fare_amount_quantiles = sdf.approxQuantile(\"fare_amount\", [0.5, 0.75, 0.9, 0.95, 0.99], 0.01)\n",
    "print(f\"50th percentile (median): {fare_amount_quantiles[0]}\")\n",
    "print(f\"75th percentile: {fare_amount_quantiles[1]}\")\n",
    "print(f\"90th percentile: {fare_amount_quantiles[2]}\")\n",
    "print(f\"95th percentile: {fare_amount_quantiles[3]}\")\n",
    "print(f\"99th percentile: {fare_amount_quantiles[4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantile analysis of the `fare_amount` provides insights into the distribution of fares:\n",
    "\n",
    "- Half of the fares are below $12.5, indicating a central tendency.\n",
    "- 75% of the fares are below $19.8, showing a modest increase from the median.\n",
    "- A sharp rise, indicating that the top 10% of fares are significantly higher, reflecting some longer or more expensive trips.\n",
    "- The top 5% of fares further increase, suggesting a small portion of trips with notably high fares.\n",
    "- A dramatic spike at the 99th percentile indicates extreme outliers, likely due to data errors or very unique, high-cost trips.\n",
    "\n",
    "=> The fare distribution is right-skewed with most fares clustered under $20. However, there are significant outliers at the upper end, which may require further investigation or handling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Quantiles for Trip Distance\n",
    "\n",
    "Calculates the 50th, 75th, 90th, 95th, and 99th percentiles of the `trip_distance` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50th percentile (median): 1.8\n",
      "75th percentile: 3.34\n",
      "90th percentile: 8.7\n",
      "95th percentile: 13.93\n",
      "99th percentile: 103319.46\n"
     ]
    }
   ],
   "source": [
    "trip_distance_quantiles = sdf.approxQuantile(\"trip_distance\", [0.5, 0.75, 0.9, 0.95, 0.99], 0.01)\n",
    "print(f\"50th percentile (median): {trip_distance_quantiles[0]}\")\n",
    "print(f\"75th percentile: {trip_distance_quantiles[1]}\")\n",
    "print(f\"90th percentile: {trip_distance_quantiles[2]}\")\n",
    "print(f\"95th percentile: {trip_distance_quantiles[3]}\")\n",
    "print(f\"99th percentile: {trip_distance_quantiles[4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantile analysis of the trip_distance provides insights into the distribution of trip distances:\n",
    "\n",
    "- Half of the trips are below 1.8 miles, indicating that most trips are short.\n",
    "- 75% of the trips are below 3.34 miles, showing a gradual increase from the median.\n",
    "- A noticeable rise at the 90th percentile, with the top 10% of trips extending beyond 8.7 miles, suggesting some longer trips.\n",
    "- The top 5% of trips are over 13.93 miles, indicating a smaller portion of significantly longer trips.\n",
    "- The extreme value at the 99th percentile (103,319.46 miles) indicates severe outliers, likely due to data errors or exceptional cases.\n",
    "\n",
    "=> The trip distance distribution is heavily skewed with most trips being short, but extreme outliers at the high end may need to be addressed for accurate analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Filtering and Feature Engineering\n",
    "\n",
    "This part performs a series of filtering operations and feature engineering steps on the DataFrame. The goal is to clean the dataset by removing outliers and irrelevant data points, as well as to create new features that could be useful for subsequent analysis or modeling.\n",
    "\n",
    "#### Filtering Operations:\n",
    "\n",
    "1. **RatecodeID Filtering**:\n",
    "   - Retains only records where `RatecodeID` is between 1 and 6 (inclusive). This helps to focus on valid trip records with known rate codes.\n",
    "\n",
    "2. **MTA Tax Filtering**:\n",
    "   - Retains records where the `mta_tax` is either 0 or 0.5, ensuring only valid and common MTA tax values are included.\n",
    "\n",
    "3. **Improvement Surcharge Filtering**:\n",
    "   - Filters records where `improvement_surcharge` is either 0.0 or 0.3, which are the typical charges seen in the dataset.\n",
    "\n",
    "4. **Airport Fee Filtering**:\n",
    "   - Retains records where `airport_fee` is either 0.0 or 1.25, which are the standard charges for trips to/from airports.\n",
    "\n",
    "5. **Store and Forward Flag Conversion**:\n",
    "   - Converts the `store_and_fwd_flag` column from categorical values ('Y', 'N') to binary (1, 0) for easier analysis. Here, 'Y' (Yes) is converted to 1, and 'N' (No) is converted to 0.\n",
    "\n",
    "6. **Passenger Count Filtering**:\n",
    "   - Filters records to retain only those with `passenger_count` between 1 and 6, which are typical and valid passenger counts for taxi rides.\n",
    "\n",
    "7. **Trip Distance Filtering**:\n",
    "   - Filters trips where `trip_distance` is greater than 0.2 miles but less than or equal to 75 miles, removing trips that are either too short or suspiciously long.\n",
    "\n",
    "8. **Fare Amount Filtering**:\n",
    "   - Retains records where `fare_amount` is between $3.00 and $200.00, focusing on reasonable fare amounts that correspond to typical taxi rides.\n",
    "\n",
    "9. **Trip Duration Calculation and Filtering**:\n",
    "   - Creates a new column `trip_duration_mins` by calculating the trip duration in minutes from `tpep_pickup_datetime` and `tpep_dropoff_datetime`.\n",
    "   - Filters records where `trip_duration_mins` is greater than 1 minute and less than or equal to 180 minutes, removing extremely short or excessively long trips.\n",
    "\n",
    "#### Feature Engineering:\n",
    "\n",
    "1. **Datetime Casting**:\n",
    "   - Converts `tpep_pickup_datetime` and `tpep_dropoff_datetime` columns to timestamp data types for accurate date and time calculations.\n",
    "\n",
    "2. **Hour and Day of Week Extraction**:\n",
    "   - Creates new columns `pickup_hour` and `dropoff_hour` to extract the hour of the day from the pickup and dropoff timestamps.\n",
    "   - Creates new columns `pickup_dayofweek` and `dropoff_dayofweek` to extract the day of the week from the pickup and dropoff timestamps.\n",
    "\n",
    "3. **Days Since Reference Date**:\n",
    "   - Creates a new column `days_since_2022_11_01` to calculate the number of days since November 1, 2022, for each trip. This feature can help capture trends or seasonality effects over time.\n",
    "\n",
    "4. **Distance-Time Interaction Term**:\n",
    "   - Creates a new interaction feature `distance_time_interaction` by multiplying `trip_distance` with `pickup_hour`. This feature might capture interactions between the time of day and the distance traveled, which could be predictive of certain outcomes.\n",
    "\n",
    "5. **Final Filtering**:\n",
    "   - Further filters records to retain only those where `days_since_2022_11_01` is between 0 and 180 days, focusing the analysis on a specific time window.\n",
    "\n",
    "#### Sampling:\n",
    "- The final step displays the first 25 rows of the filtered and enhanced DataFrame to give an overview of the resulting data structure and the new features created.\n",
    "\n",
    "This detailed data preparation ensures that the dataset is clean, relevant, and enriched with new features, which are crucial for any downstream analysis or predictive modeling tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th><th>trip_duration_mins</th><th>pickup_hour</th><th>pickup_dayofweek</th><th>dropoff_hour</th><th>dropoff_dayofweek</th><th>days_since_2022_11_01</th><th>distance_time_interaction</th></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:37:35</td><td>2022-12-01 00:47:35</td><td>1.0</td><td>2.0</td><td>1.0</td><td>0</td><td>170</td><td>237</td><td>1</td><td>8.5</td><td>3.0</td><td>0.5</td><td>3.1</td><td>0.0</td><td>0.3</td><td>15.4</td><td>2.5</td><td>0.0</td><td>10.0</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:33:26</td><td>2022-12-01 00:37:34</td><td>1.0</td><td>0.8</td><td>1.0</td><td>0</td><td>140</td><td>140</td><td>1</td><td>5.0</td><td>3.0</td><td>0.5</td><td>1.76</td><td>0.0</td><td>0.3</td><td>10.56</td><td>2.5</td><td>0.0</td><td>4.133333333333334</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:45:51</td><td>2022-12-01 00:53:16</td><td>1.0</td><td>3.0</td><td>1.0</td><td>0</td><td>141</td><td>79</td><td>3</td><td>10.0</td><td>3.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>13.8</td><td>2.5</td><td>0.0</td><td>7.416666666666667</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>2</td><td>2022-12-01 00:49:49</td><td>2022-12-01 00:54:13</td><td>1.0</td><td>0.76</td><td>1.0</td><td>0</td><td>261</td><td>231</td><td>1</td><td>5.0</td><td>0.5</td><td>0.5</td><td>1.76</td><td>0.0</td><td>0.3</td><td>10.56</td><td>2.5</td><td>0.0</td><td>4.4</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:25:25</td><td>2022-12-01 00:35:38</td><td>2.0</td><td>2.6</td><td>1.0</td><td>0</td><td>237</td><td>164</td><td>1</td><td>10.5</td><td>3.0</td><td>0.5</td><td>4.25</td><td>0.0</td><td>0.3</td><td>18.55</td><td>2.5</td><td>0.0</td><td>10.216666666666667</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>2</td><td>2022-12-01 00:05:37</td><td>2022-12-01 00:10:48</td><td>1.0</td><td>0.94</td><td>1.0</td><td>0</td><td>79</td><td>144</td><td>1</td><td>5.5</td><td>0.5</td><td>0.5</td><td>1.86</td><td>0.0</td><td>0.3</td><td>11.16</td><td>2.5</td><td>0.0</td><td>5.183333333333334</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>2</td><td>2022-12-01 00:20:12</td><td>2022-12-01 00:28:49</td><td>1.0</td><td>2.09</td><td>1.0</td><td>0</td><td>79</td><td>186</td><td>1</td><td>9.0</td><td>0.5</td><td>0.5</td><td>2.0</td><td>0.0</td><td>0.3</td><td>14.8</td><td>2.5</td><td>0.0</td><td>8.616666666666667</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:00:54</td><td>2022-12-01 00:05:41</td><td>1.0</td><td>0.8</td><td>1.0</td><td>0</td><td>142</td><td>143</td><td>1</td><td>5.5</td><td>3.0</td><td>0.5</td><td>1.85</td><td>0.0</td><td>0.3</td><td>11.15</td><td>2.5</td><td>0.0</td><td>4.783333333333333</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>2</td><td>2022-12-01 00:11:23</td><td>2022-12-01 00:30:00</td><td>1.0</td><td>7.62</td><td>1.0</td><td>0</td><td>138</td><td>255</td><td>1</td><td>24.0</td><td>0.5</td><td>0.5</td><td>5.31</td><td>0.0</td><td>0.3</td><td>31.86</td><td>0.0</td><td>1.25</td><td>18.616666666666667</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:14:29</td><td>2022-12-01 00:30:10</td><td>2.0</td><td>3.1</td><td>1.0</td><td>0</td><td>234</td><td>143</td><td>1</td><td>13.0</td><td>3.0</td><td>0.5</td><td>1.68</td><td>0.0</td><td>0.3</td><td>18.48</td><td>2.5</td><td>0.0</td><td>15.683333333333334</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:41:01</td><td>2022-12-01 00:44:17</td><td>1.0</td><td>0.5</td><td>1.0</td><td>0</td><td>48</td><td>68</td><td>1</td><td>4.5</td><td>3.0</td><td>0.5</td><td>1.65</td><td>0.0</td><td>0.3</td><td>9.95</td><td>2.5</td><td>0.0</td><td>3.2666666666666666</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:54:50</td><td>2022-12-01 01:28:18</td><td>1.0</td><td>7.4</td><td>1.0</td><td>0</td><td>230</td><td>17</td><td>1</td><td>27.5</td><td>3.0</td><td>0.5</td><td>6.25</td><td>0.0</td><td>0.3</td><td>37.55</td><td>2.5</td><td>0.0</td><td>33.46666666666667</td><td>0</td><td>5</td><td>1</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:32:15</td><td>2022-12-01 00:44:39</td><td>3.0</td><td>3.4</td><td>1.0</td><td>0</td><td>107</td><td>262</td><td>1</td><td>12.5</td><td>3.0</td><td>0.5</td><td>2.0</td><td>0.0</td><td>0.3</td><td>18.3</td><td>2.5</td><td>0.0</td><td>12.4</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:59:12</td><td>2022-12-01 01:25:47</td><td>1.0</td><td>5.8</td><td>1.0</td><td>0</td><td>161</td><td>223</td><td>1</td><td>22.0</td><td>3.0</td><td>0.5</td><td>5.15</td><td>0.0</td><td>0.3</td><td>30.95</td><td>2.5</td><td>0.0</td><td>26.583333333333332</td><td>0</td><td>5</td><td>1</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>2</td><td>2022-12-01 00:38:03</td><td>2022-12-01 01:04:05</td><td>2.0</td><td>17.08</td><td>2.0</td><td>0</td><td>132</td><td>233</td><td>1</td><td>52.0</td><td>0.0</td><td>0.5</td><td>5.0</td><td>6.55</td><td>0.3</td><td>68.1</td><td>2.5</td><td>1.25</td><td>26.033333333333335</td><td>0</td><td>5</td><td>1</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2022-12-01 00:20:09</td><td>2022-12-01 00:30:31</td><td>1.0</td><td>1.8</td><td>1.0</td><td>0</td><td>48</td><td>229</td><td>1</td><td>9.0</td><td>3.0</td><td>0.5</td><td>2.55</td><td>0.0</td><td>0.3</td><td>15.35</td><td>2.5</td><td>0.0</td><td>10.366666666666667</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>2</td><td>2022-12-01 00:03:45</td><td>2022-12-01 00:32:33</td><td>1.0</td><td>7.47</td><td>1.0</td><td>0</td><td>140</td><td>36</td><td>1</td><td>25.0</td><td>0.5</td><td>0.5</td><td>5.0</td><td>0.0</td><td>0.3</td><td>33.8</td><td>2.5</td><td>0.0</td><td>28.8</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>2</td><td>2022-12-01 00:18:19</td><td>2022-12-01 00:45:24</td><td>5.0</td><td>9.92</td><td>1.0</td><td>0</td><td>132</td><td>198</td><td>1</td><td>30.0</td><td>0.5</td><td>0.5</td><td>8.14</td><td>0.0</td><td>0.3</td><td>40.69</td><td>0.0</td><td>1.25</td><td>27.083333333333332</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>2</td><td>2022-12-01 00:39:55</td><td>2022-12-01 00:44:58</td><td>1.0</td><td>1.48</td><td>1.0</td><td>0</td><td>68</td><td>107</td><td>1</td><td>6.5</td><td>0.5</td><td>0.5</td><td>3.09</td><td>0.0</td><td>0.3</td><td>13.39</td><td>2.5</td><td>0.0</td><td>5.05</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "<tr><td>2</td><td>2022-12-01 00:50:42</td><td>2022-12-01 00:57:06</td><td>1.0</td><td>1.89</td><td>1.0</td><td>0</td><td>170</td><td>141</td><td>1</td><td>7.5</td><td>0.5</td><td>0.5</td><td>2.83</td><td>0.0</td><td>0.3</td><td>14.13</td><td>2.5</td><td>0.0</td><td>6.4</td><td>0</td><td>5</td><td>0</td><td>5</td><td>30</td><td>0.0</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+-----------+----------------+------------+-----------------+---------------------+-------------------------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|trip_duration_mins|pickup_hour|pickup_dayofweek|dropoff_hour|dropoff_dayofweek|days_since_2022_11_01|distance_time_interaction|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+-----------+----------------+------------+-----------------+---------------------+-------------------------+\n",
       "|       1| 2022-12-01 00:37:35|  2022-12-01 00:47:35|            1.0|          2.0|       1.0|                 0|         170|         237|           1|        8.5|  3.0|    0.5|       3.1|         0.0|                  0.3|        15.4|                 2.5|        0.0|              10.0|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       1| 2022-12-01 00:33:26|  2022-12-01 00:37:34|            1.0|          0.8|       1.0|                 0|         140|         140|           1|        5.0|  3.0|    0.5|      1.76|         0.0|                  0.3|       10.56|                 2.5|        0.0| 4.133333333333334|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       1| 2022-12-01 00:45:51|  2022-12-01 00:53:16|            1.0|          3.0|       1.0|                 0|         141|          79|           3|       10.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        13.8|                 2.5|        0.0| 7.416666666666667|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       2| 2022-12-01 00:49:49|  2022-12-01 00:54:13|            1.0|         0.76|       1.0|                 0|         261|         231|           1|        5.0|  0.5|    0.5|      1.76|         0.0|                  0.3|       10.56|                 2.5|        0.0|               4.4|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       1| 2022-12-01 00:25:25|  2022-12-01 00:35:38|            2.0|          2.6|       1.0|                 0|         237|         164|           1|       10.5|  3.0|    0.5|      4.25|         0.0|                  0.3|       18.55|                 2.5|        0.0|10.216666666666667|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       2| 2022-12-01 00:05:37|  2022-12-01 00:10:48|            1.0|         0.94|       1.0|                 0|          79|         144|           1|        5.5|  0.5|    0.5|      1.86|         0.0|                  0.3|       11.16|                 2.5|        0.0| 5.183333333333334|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       2| 2022-12-01 00:20:12|  2022-12-01 00:28:49|            1.0|         2.09|       1.0|                 0|          79|         186|           1|        9.0|  0.5|    0.5|       2.0|         0.0|                  0.3|        14.8|                 2.5|        0.0| 8.616666666666667|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       1| 2022-12-01 00:00:54|  2022-12-01 00:05:41|            1.0|          0.8|       1.0|                 0|         142|         143|           1|        5.5|  3.0|    0.5|      1.85|         0.0|                  0.3|       11.15|                 2.5|        0.0| 4.783333333333333|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       2| 2022-12-01 00:11:23|  2022-12-01 00:30:00|            1.0|         7.62|       1.0|                 0|         138|         255|           1|       24.0|  0.5|    0.5|      5.31|         0.0|                  0.3|       31.86|                 0.0|       1.25|18.616666666666667|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       1| 2022-12-01 00:14:29|  2022-12-01 00:30:10|            2.0|          3.1|       1.0|                 0|         234|         143|           1|       13.0|  3.0|    0.5|      1.68|         0.0|                  0.3|       18.48|                 2.5|        0.0|15.683333333333334|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       1| 2022-12-01 00:41:01|  2022-12-01 00:44:17|            1.0|          0.5|       1.0|                 0|          48|          68|           1|        4.5|  3.0|    0.5|      1.65|         0.0|                  0.3|        9.95|                 2.5|        0.0|3.2666666666666666|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       1| 2022-12-01 00:54:50|  2022-12-01 01:28:18|            1.0|          7.4|       1.0|                 0|         230|          17|           1|       27.5|  3.0|    0.5|      6.25|         0.0|                  0.3|       37.55|                 2.5|        0.0| 33.46666666666667|          0|               5|           1|                5|                   30|                      0.0|\n",
       "|       1| 2022-12-01 00:32:15|  2022-12-01 00:44:39|            3.0|          3.4|       1.0|                 0|         107|         262|           1|       12.5|  3.0|    0.5|       2.0|         0.0|                  0.3|        18.3|                 2.5|        0.0|              12.4|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       1| 2022-12-01 00:59:12|  2022-12-01 01:25:47|            1.0|          5.8|       1.0|                 0|         161|         223|           1|       22.0|  3.0|    0.5|      5.15|         0.0|                  0.3|       30.95|                 2.5|        0.0|26.583333333333332|          0|               5|           1|                5|                   30|                      0.0|\n",
       "|       2| 2022-12-01 00:38:03|  2022-12-01 01:04:05|            2.0|        17.08|       2.0|                 0|         132|         233|           1|       52.0|  0.0|    0.5|       5.0|        6.55|                  0.3|        68.1|                 2.5|       1.25|26.033333333333335|          0|               5|           1|                5|                   30|                      0.0|\n",
       "|       1| 2022-12-01 00:20:09|  2022-12-01 00:30:31|            1.0|          1.8|       1.0|                 0|          48|         229|           1|        9.0|  3.0|    0.5|      2.55|         0.0|                  0.3|       15.35|                 2.5|        0.0|10.366666666666667|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       2| 2022-12-01 00:03:45|  2022-12-01 00:32:33|            1.0|         7.47|       1.0|                 0|         140|          36|           1|       25.0|  0.5|    0.5|       5.0|         0.0|                  0.3|        33.8|                 2.5|        0.0|              28.8|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       2| 2022-12-01 00:18:19|  2022-12-01 00:45:24|            5.0|         9.92|       1.0|                 0|         132|         198|           1|       30.0|  0.5|    0.5|      8.14|         0.0|                  0.3|       40.69|                 0.0|       1.25|27.083333333333332|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       2| 2022-12-01 00:39:55|  2022-12-01 00:44:58|            1.0|         1.48|       1.0|                 0|          68|         107|           1|        6.5|  0.5|    0.5|      3.09|         0.0|                  0.3|       13.39|                 2.5|        0.0|              5.05|          0|               5|           0|                5|                   30|                      0.0|\n",
       "|       2| 2022-12-01 00:50:42|  2022-12-01 00:57:06|            1.0|         1.89|       1.0|                 0|         170|         141|           1|        7.5|  0.5|    0.5|      2.83|         0.0|                  0.3|       14.13|                 2.5|        0.0|               6.4|          0|               5|           0|                5|                   30|                      0.0|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+-----------+----------------+------------+-----------------+---------------------+-------------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the DataFrame to retain records where RatecodeID is between 1 and 6\n",
    "df_filtered = sdf.filter((col(\"RatecodeID\") >= 1) & (col(\"RatecodeID\") <= 6))\n",
    "\n",
    "# Further filter to retain records where MTA tax is either 0 or 0.5\n",
    "df_filtered = df_filtered.filter((col(\"mta_tax\") == 0) | (col(\"mta_tax\") == 0.5))\n",
    "\n",
    "# Filter to retain records where the improvement surcharge is either 0.0 or 0.3\n",
    "df_filtered = df_filtered.filter((col(\"improvement_surcharge\") == 0.0) | (col(\"improvement_surcharge\") == 0.3))\n",
    "\n",
    "# Filter to retain records where airport fee is either 0.0 or 1.25\n",
    "df_filtered = df_filtered.filter((col(\"airport_fee\") == 0.0) | (col(\"airport_fee\") == 1.25))\n",
    "\n",
    "# Convert the store_and_fwd_flag column to binary: 'Y' becomes 1, 'N' becomes 0\n",
    "df_filtered = df_filtered.withColumn(\"store_and_fwd_flag\", when(col(\"store_and_fwd_flag\") == 'Y', 1).otherwise(0))\n",
    "\n",
    "# Filter to retain records with a valid passenger count between 1 and 6\n",
    "df_filtered = df_filtered.filter((col(\"passenger_count\") >= 1.0) & (col(\"passenger_count\") <= 6.0))\n",
    "\n",
    "# Filter to retain records where trip distance is greater than 0.2 miles but less than or equal to 75 miles\n",
    "df_filtered = df_filtered.filter((col(\"trip_distance\") > 0.2) & (col(\"trip_distance\") <= 75.0))\n",
    "\n",
    "# Filter to retain records where fare amount is greater than $3.00 but less than or equal to $200.00\n",
    "df_filtered = df_filtered.filter((col(\"fare_amount\") > 3.0) & (col(\"fare_amount\") <= 200.0))\n",
    "\n",
    "# Calculate the trip duration in minutes and add it as a new column\n",
    "df_filtered = df_filtered.withColumn(\"trip_duration_mins\",\n",
    "                                     (unix_timestamp(col(\"tpep_dropoff_datetime\")) - unix_timestamp(col(\"tpep_pickup_datetime\"))) / 60)\n",
    "\n",
    "# Filter to retain records where trip duration is greater than 1 minute but less than or equal to 180 minutes\n",
    "df_filtered = df_filtered.filter((col(\"trip_duration_mins\") > 1.0) & (col(\"trip_duration_mins\") <= 180))\n",
    "\n",
    "# Convert the pickup and dropoff datetime columns to timestamp data types\n",
    "df_filtered = df_filtered.withColumn(\"tpep_pickup_datetime\", col(\"tpep_pickup_datetime\").cast(\"timestamp\")) \\\n",
    "                         .withColumn(\"tpep_dropoff_datetime\", col(\"tpep_dropoff_datetime\").cast(\"timestamp\"))\n",
    "\n",
    "# Extract hour of day and day of the week from the pickup and dropoff timestamps, add as new columns\n",
    "df_filtered = df_filtered.withColumn(\"pickup_hour\", hour(col(\"tpep_pickup_datetime\"))) \\\n",
    "                         .withColumn(\"pickup_dayofweek\", dayofweek(col(\"tpep_pickup_datetime\"))) \\\n",
    "                         .withColumn(\"dropoff_hour\", hour(col(\"tpep_dropoff_datetime\"))) \\\n",
    "                         .withColumn(\"dropoff_dayofweek\", dayofweek(col(\"tpep_dropoff_datetime\"))) \\\n",
    "                         .withColumn(\"days_since_2022_11_01\", datediff(col(\"tpep_pickup_datetime\"), lit(\"2022-11-01\")))\n",
    "\n",
    "# Filter to retain records where the trip occurred between 0 and 180 days since November 1, 2022\n",
    "df_filtered = df_filtered.filter((col(\"days_since_2022_11_01\") >= 0.0) & (col(\"days_since_2022_11_01\") <= 180))\n",
    "\n",
    "# Create an interaction term between trip distance and pickup hour, and add it as a new column\n",
    "df_filtered = df_filtered.withColumn(\"distance_time_interaction\", col(\"trip_distance\") * col(\"pickup_hour\"))\n",
    "\n",
    "# Display the first 25 rows of the filtered and processed DataFrame\n",
    "df_filtered.limit(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate and display the percentage of data retained after the filtering and cleaning process. This is an important step to understand how much of the original dataset is still available for analysis after removing unwanted or irrelevant records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 122:======================================>                  (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset contains  26.753%  of the initial dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate and display the percentage of the dataset that remains after filtering\n",
    "print('Cleaned dataset contains ', str(df_filtered.count() / sdf.count() * 100)[:6] + '%', ' of the initial dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 125:============================>                            (3 + 3) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame: 5016231 rows, 26 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "shape(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After processing, the cleaned dataset contains 26.753% of the initial dataset, with 5,016,231 rows and 26 columns.\n",
    "\n",
    "The cleaned and filtered DataFrame is saved to disk in Parquet format. This step ensures that the processed data is stored in a highly efficient, columnar storage format, making it ready for further analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save the cleaned DataFrame to a Parquet file, overwriting any existing file in the target directory\n",
    "df_filtered.write.parquet('/Users/jennymai/Desktop/data_sci/mast_project1/data/curated', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Spark session to release resources\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
